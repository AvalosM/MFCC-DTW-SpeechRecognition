{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile library with different flags\n",
    "!rm -f libspeechr*.so\n",
    "!cd .. && make clean && make AVX=false && make AVX=true\n",
    "!cp ../build/libspeechr*.so ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.ctypeslib import *\n",
    "from speechrlib import *\n",
    "import wave\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = ['four0', 'two0', 'four1', 'two1']\n",
    "audio_list = []\n",
    "samplerate = 16000\n",
    "for i in range(0,len(sample_names)):\n",
    "    audio = wave.open(\"../data/samples/\" + sample_names[i] + \".wav\")\n",
    "    length = audio.getnframes()\n",
    "    audio_list.append(np.frombuffer(audio.readframes(length), dtype=np.int16).astype(c_float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(0,4):\n",
    "    fig.add_subplot(2,2,i+1)\n",
    "    plt.plot(audio_list[i], c='red')\n",
    "    plt.title(sample_names[i])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechrlib import *\n",
    "speechr = load_speechrlib(\"./libspeechr.so\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(0,4):\n",
    "    ax = fig.add_subplot(2,2,i+1)\n",
    "    framed_audio = speechr.frame(audio_list[i].ctypes.data_as(c_float_p), len(audio_list[i]), samplerate).contents\n",
    "    data = as_array(framed_audio.data, [framed_audio.size])\n",
    "    signal = [i[0] for i in data]\n",
    "    ax.plot(signal, c='red')\n",
    "    plt.title(sample_names[i])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(0,4):\n",
    "    ax = fig.add_subplot(2,2,i+1)\n",
    "    spectrogram_matrix = speechr.mel_spectrogram(audio_list[i].ctypes.data_as(c_float_p), len(audio_list[i]), samplerate)\n",
    "    data = matrixf_as_array(spectrogram_matrix)\n",
    "    ax.imshow(data.T, origin='lower', cmap='jet', aspect='auto')\n",
    "    plt.xticks(np.linspace(0, data.shape[0]-1, num=5), np.linspace(0, 1, num=5))\n",
    "    plt.yticks(np.linspace(0, data.shape[1]-1, num=5),np.trunc(np.logspace(np.log2(300),np.log2(8000), base=2, num=5)))\n",
    "    plt.title(sample_names[i])\n",
    "    plt.xlabel(\"Time(s)\");\n",
    "    plt.ylabel(\"Frequency\");\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_list = []\n",
    "for i in range(0, len(audio_list)):\n",
    "    mfcc_matrix = speechr.mfcc(audio_list[i].ctypes.data_as(c_float_p), len(audio_list[i]), samplerate)\n",
    "    feature_matrix_list.append(mfcc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(0,4):\n",
    "    ax = fig.add_subplot(2,2,i+1)\n",
    "    data = matrixf_as_array(feature_matrix_list[i])\n",
    "    ax.imshow(data.T, origin='lower', cmap='jet', aspect='auto')\n",
    "    plt.xticks(np.linspace(0, data.shape[0]-1, num=5), np.linspace(0, 1, num=5))\n",
    "    plt.yticks(np.arange(0,12,1), np.arange(1,13,1))\n",
    "    plt.title(sample_names[i])\n",
    "    plt.xlabel(\"Time(s)\");\n",
    "    plt.ylabel(\"MFCC feature\");\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "fig = plt.figure()\n",
    "subplot_num = 1\n",
    "for i in range(0,4):\n",
    "    for j in range(i+1,4):\n",
    "        fig.add_subplot(2,3,subplot_num)\n",
    "        subplot_num = subplot_num + 1\n",
    "        mfcc1 = matrixf_as_array(feature_matrix_list[i])\n",
    "        mfcc2 = matrixf_as_array(feature_matrix_list[j])\n",
    "        dmatrix = spatial.distance_matrix(mfcc1, mfcc2)\n",
    "        im = plt.imshow(dmatrix, aspect='auto', interpolation='none', cmap='hot', origin='lower')\n",
    "        ax = fig.gca()\n",
    "        plt.title(sample_names[i] + ' vs. ' + sample_names[j])\n",
    "        cbar = ax.figure.colorbar(im, ax=ax)\n",
    "        cbar.ax.set_ylabel('Distance', rotation=-90, va=\"bottom\");\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_estimations = pd.DataFrame(columns=['sample_name'] + sample_names)\n",
    "similarity_estimations['sample_name'] = sample_names\n",
    "for i in range(0,4):\n",
    "    for j in range(0,4):\n",
    "        value = 0 if i == j else speechr.dtw(feature_matrix_list[i], feature_matrix_list[j])\n",
    "        similarity_estimations[sample_names[i]][j] = value\n",
    "print(similarity_estimations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('knn-classifier')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f216903615eb8d87c55bd710f78c97e5d3ece4431102e2f634bf3faeb40be796"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
