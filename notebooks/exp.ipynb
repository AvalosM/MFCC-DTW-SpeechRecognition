{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f libspeechr.so\n",
    "!cd .. && make clean && make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.ctypeslib import *\n",
    "from speechrlib import *\n",
    "import wave\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../results/tests/fft_sinewave.csv', header=None)\n",
    "size = data.shape[0]\n",
    "freq = range(0, size, 1)\n",
    "plt.plot(freq, data[0][:size]);\n",
    "plt.show()\n",
    "\n",
    "data = pd.read_csv('../results/tests/fft_fftsinewave.csv', header=None).to_numpy()\n",
    "size = data.shape[0]\n",
    "freq = range(0, size, 1)\n",
    "plt.plot(freq, np.abs(data[:size])**2);\n",
    "plt.show()\n",
    "\n",
    "data = pd.read_csv('../results/tests/fft_wavesum.csv', header=None)\n",
    "size = data.shape[0]\n",
    "print(size)\n",
    "freq = range(0, size, 1)\n",
    "plt.plot(freq, data[0][:size]);\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('../results/tests/fft_fftwavesum.csv', header=None).to_numpy()\n",
    "size = data.shape[0]\n",
    "freq = range(0, size, 1)\n",
    "plt.plot(freq, np.abs(data[:size])**2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = ['four0', 'two0', 'four1', 'two1']\n",
    "audio_list = []\n",
    "samplerate = 16000\n",
    "for i in range(0,len(sample_names)):\n",
    "    audio = wave.open(\"../data/samples/\" + sample_names[i] + \".wav\")\n",
    "    length = audio.getnframes()\n",
    "    audio_list.append(np.frombuffer(audio.readframes(length), dtype=np.int16).astype(c_float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(0,4):\n",
    "    fig.add_subplot(2,2,i+1)\n",
    "    plt.plot(audio_list[i], c='red')\n",
    "    plt.title(sample_names[i])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(0,4):\n",
    "    ax = fig.add_subplot(2,2,i+1)\n",
    "    spectrogram_matrix = speechr.melspectrogram(audio_list[i].ctypes.data_as(c_float_p), len(audio_list[i]), samplerate).contents\n",
    "    rows = spectrogram_matrix.rows\n",
    "    cols = spectrogram_matrix.cols\n",
    "    data = as_array(spectrogram_matrix.data,[rows*cols]).reshape(rows,cols)\n",
    "    ax.imshow(data.T, origin='lower', cmap='jet', aspect='auto')\n",
    "    plt.xticks(np.linspace(0, data.shape[0]-1, num=5), np.linspace(0, 1, num=5))\n",
    "    plt.yticks(np.linspace(0, data.shape[1]-1, num=5),np.trunc(np.logspace(np.log2(300),np.log2(8000), base=2, num=5)))\n",
    "    plt.title(sample_names[i])\n",
    "    plt.xlabel(\"Time(s)\");\n",
    "    plt.ylabel(\"Frequency\");\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_list = []\n",
    "for i in range(0, len(audio_list)):\n",
    "    mfcc_matrix = speechr.mfcc(audio_list[i].ctypes.data_as(c_float_p), len(audio_list[i]), samplerate).contents\n",
    "    rows = mfcc_matrix.rows\n",
    "    cols = mfcc_matrix.cols\n",
    "    feature_matrix_list.append(as_array(mfcc_matrix.data,[rows*cols]).reshape(rows,cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(0,4):\n",
    "    ax = fig.add_subplot(2,2,i+1)\n",
    "    data = feature_matrix_list[i]\n",
    "    ax.imshow(data.T, origin='lower', cmap='jet', aspect='auto')\n",
    "    plt.xticks(np.linspace(0, data.shape[0]-1, num=5), np.linspace(0, 1, num=5))\n",
    "    plt.yticks(np.arange(0,12,1), np.arange(1,13,1))\n",
    "    plt.title(sample_names[i])\n",
    "    plt.xlabel(\"Time(s)\");\n",
    "    plt.ylabel(\"MFCC feature\");\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "fig = plt.figure()\n",
    "subplot_num = 1\n",
    "for i in range(0,4):\n",
    "    for j in range(i+1,4):\n",
    "        fig.add_subplot(2,3,subplot_num)\n",
    "        subplot_num = subplot_num + 1\n",
    "        mfcc1 = feature_matrix_list[i]\n",
    "        mfcc2 = feature_matrix_list[j]\n",
    "        dmatrix = spatial.distance_matrix(mfcc1, mfcc2)\n",
    "        im = plt.imshow(dmatrix, aspect='auto', interpolation='none', cmap='hot', origin='lower')\n",
    "        ax = fig.gca()\n",
    "        plt.title(sample_names[i] + ' vs. ' + sample_names[j])\n",
    "        cbar = ax.figure.colorbar(im, ax=ax)\n",
    "        cbar.ax.set_ylabel('Distance', rotation=-90, va=\"bottom\");\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('speechrecognition')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68ad91fe56bf228a59db514315867f7d3e19b6c669e7a0fbd4d5254dbb53db91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
